{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860a4923",
   "metadata": {},
   "source": [
    "# PA4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b96d62-0b31-445f-bae3-06e01819a865",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ceebd-90d5-4532-b7c1-eb0ba58577b6",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68083152-0a3d-41fd-8de8-f9477c1d48cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.64 sec.\n",
      "Accuracy: 0.7919.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardhua/dev/venv/lib/python3.9/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aml_perceptron import Perceptron, SparsePerceptron\n",
    "\n",
    "# This function reads the corpus, returns a list of documents, and a list\n",
    "# of their corresponding polarity labels. \n",
    "def read_data(corpus_file):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, y, _, x = line.split(maxsplit=3)\n",
    "            X.append(x.strip())\n",
    "            Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    # Read all the documents.\n",
    "    X, Y = read_data('data/all_sentiment_shuffled.txt')\n",
    "    \n",
    "    # Split into training and test parts.\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "    # Set up the preprocessing steps and the classifier.\n",
    "    pipeline = make_pipeline(\n",
    "        TfidfVectorizer(),\n",
    "        SelectKBest(k=1000),\n",
    "        Normalizer(),\n",
    "\n",
    "        # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "        Perceptron()  \n",
    "    )\n",
    "\n",
    "    # Train the classifier.\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    t1 = time.time()\n",
    "    print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "\n",
    "    # Evaluate on the test set.\n",
    "    Yguess = pipeline.predict(Xtest)\n",
    "    print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97125de7-f937-4654-9f2d-023297d5dc66",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18530d62-9ad0-4fd4-b062-4ec11741470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 2.97 sec.\n",
      "Accuracy: 0.8363.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pegasos import Pegasos\n",
    "\n",
    "# This function reads the corpus, returns a list of documents, and a list\n",
    "# of their corresponding polarity labels. \n",
    "def read_data(corpus_file):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, y, _, x = line.split(maxsplit=3)\n",
    "            X.append(x.strip())\n",
    "            Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    # Read all the documents.\n",
    "    X, Y = read_data('data/all_sentiment_shuffled.txt')\n",
    "    \n",
    "    # Split into training and test parts.\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "    # Set up the preprocessing steps and the classifier.\n",
    "    pipeline = make_pipeline(\n",
    "        TfidfVectorizer(),\n",
    "        SelectKBest(k=1000),\n",
    "        Normalizer(),\n",
    "\n",
    "        # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "        Pegasos()  \n",
    "    )\n",
    "\n",
    "    # Train the classifier.\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    t1 = time.time()\n",
    "    print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "\n",
    "    # Evaluate on the test set.\n",
    "    Yguess = pipeline.predict(Xtest)\n",
    "    print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088073b-a4eb-4bee-9eb3-c96ce6297823",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfbe01df-327a-4e94-bebe-870590de741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 5.18 sec.\n",
      "Accuracy: 0.8376.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pegasos import LogisticRegression\n",
    "\n",
    "# This function reads the corpus, returns a list of documents, and a list\n",
    "# of their corresponding polarity labels. \n",
    "def read_data(corpus_file):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, y, _, x = line.split(maxsplit=3)\n",
    "            X.append(x.strip())\n",
    "            Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "    # Read all the documents.\n",
    "    X, Y = read_data('data/all_sentiment_shuffled.txt')\n",
    "    \n",
    "    # Split into training and test parts.\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "    # Set up the preprocessing steps and the classifier.\n",
    "    pipeline = make_pipeline(\n",
    "        TfidfVectorizer(),\n",
    "        SelectKBest(k=1000),\n",
    "        Normalizer(),\n",
    "\n",
    "        # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "        LogisticRegression()  \n",
    "    )\n",
    "\n",
    "    # Train the classifier.\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    t1 = time.time()\n",
    "    print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "\n",
    "    # Evaluate on the test set.\n",
    "    Yguess = pipeline.predict(Xtest)\n",
    "    print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e09cf6-528f-4d86-8737-77e72de57091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
