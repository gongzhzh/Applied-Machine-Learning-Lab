{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860a4923",
   "metadata": {},
   "source": [
    "# PA4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee72eeb-ab9b-4ff8-b7ef-ab7c5fe35e05",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d52816-0bb5-4313-97d0-753106b6e10d",
   "metadata": {},
   "source": [
    "In this predictive system, the \"mystery\" here is that the second dataset encodes an XOR-style pattern, which no strictly linear classifier can perfectly fit. \n",
    "\n",
    "In the first dataset, you can easily draw a single straight-line in the four-dimensional one-hot feature space and separate the \"sun\" from the others. That's why the perceptron can achieve 100% accuracy with the first dataset.\n",
    "\n",
    "However, there is a XOR in the second dataset, which means it's not linearly separable. Since both the perceptron and linearSVC can only learn linear decision boundaries, they cannot solve this XOR pattern.\n",
    "\n",
    "We tried two solutions to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71667483-8f9e-4277-a98f-ba4a147b63ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X1 = [{'city':'Gothenburg', 'month':'July'},\n",
    "      {'city':'Gothenburg', 'month':'December'},\n",
    "      {'city':'Paris', 'month':'July'},\n",
    "      {'city':'Paris', 'month':'December'}]\n",
    "Y1 = ['rain', 'rain', 'sun', 'rain']\n",
    "\n",
    "X2 = [{'city':'Sydney', 'month':'July'},\n",
    "      {'city':'Sydney', 'month':'December'},\n",
    "      {'city':'Paris', 'month':'July'},\n",
    "      {'city':'Paris', 'month':'December'}]\n",
    "Y2 = ['rain', 'sun', 'sun', 'rain']\n",
    "\n",
    "classifier1 = make_pipeline(DictVectorizer(), Perceptron(max_iter=10))\n",
    "classifier1.fit(X1, Y1)\n",
    "guesses1 = classifier1.predict(X1)\n",
    "print(accuracy_score(Y1, guesses1))\n",
    "\n",
    "classifier2 = make_pipeline(DictVectorizer(), Perceptron(max_iter=10))\n",
    "#classifier2 = make_pipeline(DictVectorizer(), LinearSVC())\n",
    "classifier2.fit(X2, Y2)\n",
    "guesses2 = classifier2.predict(X2)\n",
    "print(accuracy_score(Y2, guesses2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0b19c-2ac0-4374-8358-f94aa85d07d1",
   "metadata": {},
   "source": [
    "**Add an intrerction feature**   \n",
    "We added an interaction feature to introduce a new feature (i.e., city_month) so that \"Sydney_July\" becomes its own one-hot. Thus, a linear model on those will fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d7905f-2ca5-44cc-93a8-0c62affe7b2f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'city': 'Sydney', 'month': 'July', 'city_month': 'Sydney_July'}, {'city': 'Sydney', 'month': 'December', 'city_month': 'Sydney_December'}, {'city': 'Paris', 'month': 'July', 'city_month': 'Paris_July'}, {'city': 'Paris', 'month': 'December', 'city_month': 'Paris_December'}]\n"
     ]
    }
   ],
   "source": [
    "X2_inter = []\n",
    "for x in X2:\n",
    "    xi = x.copy()\n",
    "    xi['city_month'] = f\"{x['city']}_{x['month']}\"\n",
    "    X2_inter.append(xi)\n",
    "\n",
    "print(X2_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d82977f-c741-4930-98e7-4c6da5e2ef72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with interaction: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    Perceptron(max_iter=10)\n",
    ")\n",
    "clf.fit(X2_inter, Y2)\n",
    "print(\"Accuracy with interaction:\", accuracy_score(Y2, clf.predict(X2_inter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715dfb4-2283-42da-ba3b-6a626109f918",
   "metadata": {},
   "source": [
    "**Use a non-linear mode**  \n",
    "Another aspect is to use an RBF kernel to draw a non-linear boundary in the high-dimensional feature space.\n",
    "\n",
    "RBF can project the data into a high-dimensional space; thus, it can be separated by a curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d48a811a-d4d8-4e5d-b447-177df05c8c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf_rbf = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    SVC(kernel='rbf', gamma='scale')   \n",
    ")\n",
    "clf_rbf.fit(X2, Y2)\n",
    "print(\"RBF SVM accuracy:\", accuracy_score(Y2, clf_rbf.predict(X2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b96d62-0b31-445f-bae3-06e01819a865",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516406f1-3c54-40dd-8343-e9fe333b76b0",
   "metadata": {},
   "source": [
    "### Experiment  \n",
    "We run the experiment, and the result is around the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68083152-0a3d-41fd-8de8-f9477c1d48cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1.54 sec.\n",
      "Accuracy: 0.7919.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aml_perceptron import Perceptron, SparsePerceptron\n",
    "\n",
    "# This function reads the corpus, returns a list of documents, and a list\n",
    "# of their corresponding polarity labels. \n",
    "def read_data(corpus_file):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, y, _, x = line.split(maxsplit=3)\n",
    "            X.append(x.strip())\n",
    "            Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    # Read all the documents.\n",
    "    X, Y = read_data('data/all_sentiment_shuffled.txt')\n",
    "    \n",
    "    # Split into training and test parts.\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "    # Set up the preprocessing steps and the classifier.\n",
    "    pipeline = make_pipeline(\n",
    "        TfidfVectorizer(),\n",
    "        SelectKBest(k=1000),\n",
    "        Normalizer(),\n",
    "\n",
    "        # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "        Perceptron()  \n",
    "    )\n",
    "\n",
    "    # Train the classifier.\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    t1 = time.time()\n",
    "    print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "\n",
    "    # Evaluate on the test set.\n",
    "    Yguess = pipeline.predict(Xtest)\n",
    "    print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97125de7-f937-4654-9f2d-023297d5dc66",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1004ffa-4290-4dc8-8d3f-0f9f0a36cbfb",
   "metadata": {},
   "source": [
    "We first checked the consistency of the label and the outlier of the dataset. We didn't find any inconsistency or outlier issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1969bc6d-ceab-4dff-8530-bc837a9750ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'pos': 6000, 'neg': 5914})\n",
      "Outlier X: 0\n",
      "Outlier Y: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X, Y = read_data('data/all_sentiment_shuffled.txt')\n",
    "print(Counter(Y))\n",
    "Xs = pd.Series(X)\n",
    "Ys = pd.Series(Y)\n",
    "print(\"Outlier X:\", Xs.isnull().sum())\n",
    "print(\"Outlier Y:\",Ys.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a39de7-8e51-497f-ad39-47008c76920e",
   "metadata": {},
   "source": [
    "We converted the pseudocode into Python code.\n",
    "\n",
    "The sanity check we run showed that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18530d62-9ad0-4fd4-b062-4ec11741470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 7.54 sec.\n",
      "Accuracy: 0.8363.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pegasos import Pegasos\n",
    "\n",
    "# This function reads the corpus, returns a list of documents, and a list\n",
    "# of their corresponding polarity labels. \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    # Read all the documents.\n",
    "    X, Y = read_data('data/all_sentiment_shuffled.txt')\n",
    "    \n",
    "    # Split into training and test parts.\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "    # Set up the preprocessing steps and the classifier.\n",
    "    pipeline = make_pipeline(\n",
    "        TfidfVectorizer(),\n",
    "        SelectKBest(k=1000),\n",
    "        Normalizer(),\n",
    "\n",
    "        # NB that this is our Pegasos. See the implementation inthe according .py file\n",
    "        Pegasos()  \n",
    "    )\n",
    "\n",
    "    # Train the classifier.\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    t1 = time.time()\n",
    "    print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "\n",
    "    # Evaluate on the test set.\n",
    "    Yguess = pipeline.predict(Xtest)\n",
    "    print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088073b-a4eb-4bee-9eb3-c96ce6297823",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfbe01df-327a-4e94-bebe-870590de741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 15.59 sec.\n",
      "Accuracy: 0.8376.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pegasos import LogisticRegression\n",
    "\n",
    "# This function reads the corpus, returns a list of documents, and a list\n",
    "# of their corresponding polarity labels. \n",
    "def read_data(corpus_file):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, y, _, x = line.split(maxsplit=3)\n",
    "            X.append(x.strip())\n",
    "            Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "    # Read all the documents.\n",
    "    X, Y = read_data('data/all_sentiment_shuffled.txt')\n",
    "    \n",
    "    # Split into training and test parts.\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "    # Set up the preprocessing steps and the classifier.\n",
    "    pipeline = make_pipeline(\n",
    "        TfidfVectorizer(),\n",
    "        SelectKBest(k=1000),\n",
    "        Normalizer(),\n",
    "\n",
    "        # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "        LogisticRegression()  \n",
    "    )\n",
    "\n",
    "    # Train the classifier.\n",
    "    t0 = time.time()\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    t1 = time.time()\n",
    "    print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "\n",
    "    # Evaluate on the test set.\n",
    "    Yguess = pipeline.predict(Xtest)\n",
    "    print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e09cf6-528f-4d86-8737-77e72de57091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
