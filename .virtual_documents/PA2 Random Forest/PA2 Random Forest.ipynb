








import pandas as pd
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction import DictVectorizer
from sklearn.tree import DecisionTreeClassifier


train_data = pd.read_csv('Data/adult_train.csv')
test_data = pd.read_csv('Data/adult_test.csv')

print(test_data)


train_data.head()








n_cols = len(train_data.columns)
Xtrain_dicts = train_data.iloc[:, :n_cols-1].to_dict('records')
Ytrain = train_data.iloc[:, n_cols-1]
Xtest_dicts = test_data.iloc[:, :n_cols-1].to_dict('records')
Ytest = test_data.iloc[:, n_cols-1]


# Check the first record in the training data
Xtrain_dicts[0]





dv = DictVectorizer()
X_train_encoded = dv.fit_transform(Xtrain_dicts)
X_test_encoded = dv.transform(Xtrain_dicts)
# transfrom to DataFrame to exhibit
X_train_df = pd.DataFrame(X_train_encoded.toarray(), columns=dv.get_feature_names_out())
print(X_train_df.head())
X_test_df = pd.DataFrame(X_test_encoded.toarray(), columns=dv.get_feature_names_out())
print(X_test_df.head())








from sklearn.metrics import accuracy_score
from sklearn.pipeline import make_pipeline
pipeline = make_pipeline(
  DictVectorizer(),
  DecisionTreeClassifier()
)
pipeline.fit(Xtrain_dicts, Ytrain)
accuracy_score(Ytest, pipeline.predict(Xtest_dicts))





import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt

def plot_learning_curves(X_train, Y_train, X_test, Y_test, max_depths):
    train_scores = []
    test_scores = []
    
    for depth in max_depths:
        reg = DecisionTreeClassifier(max_depth=depth)
        reg.fit(X_train, Y_train)
        train_scores.append(reg.score(X_train, Y_train))
        test_scores.append(reg.score(X_test, Y_test))
    
    plt.figure(figsize=(10, 6))
    plt.plot(max_depths, train_scores, label='Training score', marker='o')
    plt.plot(max_depths, test_scores, label='Test score', marker='x')
    plt.xlabel('Tree depth')
    plt.ylabel('accuracy score')
    plt.title('Decision Tree Classifier')
    plt.legend()
    plt.grid(True)
    plt.show()


train_data = pd.read_csv('Data/adult_train.csv')
test_data = pd.read_csv('Data/adult_test.csv')

n_cols = len(train_data.columns)
Xtrain_dicts = train_data.iloc[:, :n_cols-1].to_dict('records')
Ytrain = train_data.iloc[:, n_cols-1]


Xtest_dicts = test_data.iloc[:, :n_cols-1].to_dict('records')
Ytest = test_data.iloc[:, n_cols-1]

dv = DictVectorizer()
X_train_encoded = dv.fit_transform(Xtrain_dicts)
X_test_encoded = dv.transform(Xtest_dicts)
X_train_df = pd.DataFrame(X_train_encoded.toarray(), columns=dv.get_feature_names_out())
X_test_df = pd.DataFrame(X_test_encoded.toarray(), columns=dv.get_feature_names_out())


# print(f"num train: {len(X_train_encoded)}num test: {len(X_test_encoded)}")
plot_learning_curves(X_train_encoded, Ytrain, X_test_encoded, Ytest, range(1, 12))


import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

import matplotlib.pyplot as plt

def plot_learning_curves(X_train, Y_train, X_test, Y_test, max_depths, n_estimators_list):
    for n in n_estimators_list:
        train_scores = []
        test_scores = []
        for depth in max_depths:
            reg = RandomForestClassifier(max_depth=depth, n_estimators = n, n_jobs = 4)
            reg.fit(X_train, Y_train)
            train_scores.append(reg.score(X_train, Y_train))
            test_scores.append(reg.score(X_test, Y_test))
        
        plt.figure(figsize=(10, 6))
        plt.plot(max_depths, train_scores, label='Training score', marker='o')
        plt.plot(max_depths, test_scores, label='Test score', marker='x')
        plt.xlabel('Tree depth')
        plt.ylabel('accuracy rate')
        plt.title(f'Ensemble size n = {n}')
        plt.legend()
        plt.grid(True)
        plt.show()


train_data = pd.read_csv('Data/adult_train.csv')
test_data = pd.read_csv('Data/adult_test.csv')

n_cols = len(train_data.columns)
Xtrain_dicts = train_data.iloc[:, :n_cols-1].to_dict('records')
Ytrain = train_data.iloc[:, n_cols-1]


Xtest_dicts = test_data.iloc[:, :n_cols-1].to_dict('records')
Ytest = test_data.iloc[:, n_cols-1]

dv = DictVectorizer()
X_train_encoded = dv.fit_transform(Xtrain_dicts)
X_test_encoded = dv.transform(Xtest_dicts)
X_train_df = pd.DataFrame(X_train_encoded.toarray(), columns=dv.get_feature_names_out())
X_test_df = pd.DataFrame(X_test_encoded.toarray(), columns=dv.get_feature_names_out())


# print(f"num train: {len(X_train_encoded)}num test: {len(X_test_encoded)}")
plot_learning_curves(X_train_encoded, Ytrain, X_test_encoded, Ytest, range(1, 12), [1, 50, 100, 500])











from sklearn.metrics import classification_report

# Build pipeline: DictVectorizer + RandomForest
pipeline = Pipeline([
    ('vec', DictVectorizer(sparse=False)),
    ('clf', DecisionTreeClassifier(random_state=42))
])

# Train the model
pipeline.fit(Xtrain_dicts, Ytrain)
# Evaluate
y_pred = pipeline.predict(Xtest_dicts)
print(classification_report(Ytest, y_pred))





from sklearn.metrics import classification_report

# Build pipeline: DictVectorizer + RandomForest
pipeline = Pipeline([
    ('vec', DictVectorizer(sparse=False)),
    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))
])

# Train the model
pipeline.fit(Xtrain_dicts, Ytrain)
# Evaluate
y_pred = pipeline.predict(Xtest_dicts)
print(classification_report(Ytest, y_pred))





import numpy as np

# Access vectorizer and classifier from pipeline
vec = pipeline.steps[0][1]
clf = pipeline.steps[1][1]

# Get feature names and their importance scores
feature_names = vec.feature_names_
importances = clf.feature_importances_

# Sort by importance (descending)
indices = np.argsort(importances)[::-1]

# Display top features
print("Top 10 features by importance:")
for i in range(10):
    print(f"{feature_names[indices[i]]}: {importances[indices[i]]:.4f}")







